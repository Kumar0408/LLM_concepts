{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5366a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "here = Path.cwd().resolve()\n",
    "repo_root = here if (here / \"src\").exists() else here.parents[1]\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e288298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81fa87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cddd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gpt_blocks.data_loader import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea6caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c4bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "raw_text, batch_size=8, max_length=max_length,\n",
    "stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b95b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8975a440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2134,  1.2211,  0.3301,  ...,  0.8280, -0.3973,  0.7939],\n",
       "         [ 0.9694,  1.2444, -1.3146,  ..., -2.0704,  0.0074,  0.0206],\n",
       "         [ 0.0369,  0.2536, -0.5361,  ...,  0.3765, -0.4631, -2.0810],\n",
       "         [-0.9944,  1.6484,  0.6639,  ..., -0.0684,  0.3267, -0.5061]],\n",
       "\n",
       "        [[-0.0610,  0.2250,  0.6774,  ..., -1.1411,  0.0616,  0.3454],\n",
       "         [-0.2939,  1.1642, -2.4171,  ..., -0.4432,  2.1483,  0.5958],\n",
       "         [-0.9705,  1.5022, -1.1859,  ..., -0.5569,  1.7828, -0.3870],\n",
       "         [-0.7826,  0.0840,  1.5790,  ...,  0.0882, -0.0665,  0.1866]],\n",
       "\n",
       "        [[ 0.1592,  1.7994, -0.2480,  ...,  0.2744,  0.9752, -0.0873],\n",
       "         [-1.4104, -1.8607,  1.5669,  ..., -0.4709,  0.4952,  1.5287],\n",
       "         [ 0.3872, -1.2531, -0.1333,  ...,  0.3078, -0.8653, -0.0966],\n",
       "         [ 0.1558,  0.4309, -1.3325,  ...,  2.2045, -0.0404,  0.0356]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9477, -0.6950,  0.6029,  ...,  0.4806, -1.1319,  1.9854],\n",
       "         [-0.6073,  0.8065, -0.0648,  ..., -2.0335,  1.6501,  0.7270],\n",
       "         [-0.3338, -1.3006, -1.3046,  ..., -0.4119,  1.8650, -2.7995],\n",
       "         [ 0.1820,  0.8286,  1.1112,  ..., -0.7984, -0.4019,  0.2254]],\n",
       "\n",
       "        [[ 2.3786,  2.0518,  1.4186,  ...,  0.6607, -1.8091,  0.2398],\n",
       "         [-0.2035,  0.7205, -0.0853,  ...,  0.2928,  1.7857, -0.1276],\n",
       "         [ 0.1786, -0.3218, -1.3048,  ...,  0.9442, -0.7194,  2.2562],\n",
       "         [-1.4457, -0.9004, -0.6989,  ..., -1.6228,  1.1771,  0.0783]],\n",
       "\n",
       "        [[ 0.1786, -0.3218, -1.3048,  ...,  0.9442, -0.7194,  2.2562],\n",
       "         [-1.2828, -0.4025,  0.8007,  ..., -1.2828, -1.9986, -0.3090],\n",
       "         [-1.0018, -0.8641,  1.0049,  ...,  0.3171,  0.2139,  0.6107],\n",
       "         [-0.1811,  0.5825,  2.0462,  ..., -1.0437,  0.9082, -0.2947]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205960ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch 1 - 4 tokens - 256 embedding dimensions\n",
    "token_embeddings[:][0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb90d74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f785e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7668,  0.2183,  0.1065,  ..., -0.0249, -1.7862,  0.3125],\n",
       "        [ 0.9664, -2.4627,  0.5354,  ..., -0.5696,  0.3536,  0.7189],\n",
       "        [ 0.5135,  1.1237, -0.3547,  ...,  0.7116, -0.7971, -0.3304],\n",
       "        [ 0.6905,  0.8488, -1.7337,  ..., -1.3906,  1.6632, -0.9377]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f99a18b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "# add position embeddings to token embeddings\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "309278b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4466,  1.4393,  0.4365,  ...,  0.8031, -2.1835,  1.1064],\n",
       "         [ 1.9358, -1.2183, -0.7791,  ..., -2.6400,  0.3610,  0.7395],\n",
       "         [ 0.5503,  1.3774, -0.8908,  ...,  1.0881, -1.2603, -2.4115],\n",
       "         [-0.3039,  2.4973, -1.0698,  ..., -1.4591,  1.9900, -1.4438]],\n",
       "\n",
       "        [[ 0.7058,  0.4433,  0.7838,  ..., -1.1660, -1.7247,  0.6579],\n",
       "         [ 0.6725, -1.2985, -1.8817,  ..., -1.0128,  2.5019,  1.3148],\n",
       "         [-0.4571,  2.6260, -1.5406,  ...,  0.1547,  0.9856, -0.7174],\n",
       "         [-0.0921,  0.9328, -0.1547,  ..., -1.3024,  1.5967, -0.7511]],\n",
       "\n",
       "        [[ 0.9260,  2.0177, -0.1416,  ...,  0.2495, -0.8111,  0.2252],\n",
       "         [-0.4441, -4.3234,  2.1024,  ..., -1.0405,  0.8488,  2.2477],\n",
       "         [ 0.9007, -0.1294, -0.4880,  ...,  1.0194, -1.6624, -0.4270],\n",
       "         [ 0.8463,  1.2797, -3.0662,  ...,  0.8139,  1.6229, -0.9021]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7145, -0.4768,  0.7093,  ...,  0.4557, -2.9182,  2.2979],\n",
       "         [ 0.3590, -1.6562,  0.4706,  ..., -2.6031,  2.0036,  1.4459],\n",
       "         [ 0.1796, -0.1768, -1.6593,  ...,  0.2997,  1.0678, -3.1299],\n",
       "         [ 0.8725,  1.6774, -0.6225,  ..., -2.1890,  1.2613, -0.7124]],\n",
       "\n",
       "        [[ 3.1454,  2.2701,  1.5251,  ...,  0.6358, -3.5953,  0.5523],\n",
       "         [ 0.7629, -1.7421,  0.4501,  ..., -0.2768,  2.1393,  0.5913],\n",
       "         [ 0.6921,  0.8019, -1.6595,  ...,  1.6558, -1.5165,  1.9258],\n",
       "         [-0.7553, -0.0515, -2.4326,  ..., -3.0135,  2.8404, -0.8594]],\n",
       "\n",
       "        [[ 0.9454, -0.1036, -1.1983,  ...,  0.9193, -2.5056,  2.5687],\n",
       "         [-0.3165, -2.8652,  1.3362,  ..., -1.8524, -1.6450,  0.4099],\n",
       "         [-0.4884,  0.2596,  0.6501,  ...,  1.0287, -0.5832,  0.2802],\n",
       "         [ 0.5094,  1.4313,  0.3125,  ..., -2.4343,  2.5714, -1.2324]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-concepts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
